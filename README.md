# CIFAR-10-Image-Classification-using-Custom-Convolutional-Neural-Network
Developed a CNN architecture for CIFAR-10 classification with intermediate blocks containing convolutional layers, batch normalization, ReLU activation, and dropout, followed by fully connected layers for output.
Applied hyperparameters including batch size of 128, learning rate of 0.001, 100 epochs, 3 intermediate blocks, and Adam optimizer with OneCycleLR scheduler, using normalization, random horizontal flip, and ToTensor for data augmentation.
Achieved final test accuracy of 72.41% 
